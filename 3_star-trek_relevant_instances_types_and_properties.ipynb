{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickle/star-trek_only_relevant_properties_dict.pickle', 'rb') as f:\n",
    "    only_relevant_properties_dict = pickle.load(f)\n",
    "\n",
    "with open('pickle/star-trek_only_relevant_types_dict.pickle', 'rb') as f:\n",
    "    only_relevant_types_dict = pickle.load(f)\n",
    "\n",
    "with open('pickle/star-trek_all_instances_and_types_dict.pickle', 'rb') as f:\n",
    "    all_instances_and_types_dict = pickle.load(f)\n",
    "\n",
    "with open('pickle/star-trek_hierarchy_graph.pickle', 'rb') as f:\n",
    "    hierarchy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_direct_superclasses(c):\n",
    "    all_neighbors = hierarchy.neighbors(c)\n",
    "    direct_superclasses = list(filter(lambda x: hierarchy[c][x]['type'] == 'is_subclass_of', all_neighbors))\n",
    "    return direct_superclasses\n",
    "\n",
    "def get_superclasses(c):\n",
    "    direct_superclasses = get_direct_superclasses(c)\n",
    "    if not direct_superclasses:\n",
    "        superclasses = [[c]]\n",
    "    else:\n",
    "        superclasses = [[c] + spclsss for c2 in direct_superclasses for spclsss in get_superclasses(c2)]\n",
    "    return superclasses\n",
    "\n",
    "def is_subclass_of(c1, c2):\n",
    "    return any(map(lambda x: c2 in x, get_superclasses(c1)))\n",
    "\n",
    "def get_closest_class(c, cs):\n",
    "    cs = list(cs.keys())\n",
    "    lengths = []\n",
    "    for c2 in cs:\n",
    "        try:\n",
    "            # WARNING: if there is more than one shortest path, then it returns only one of them\n",
    "            length = nx.shortest_path_length(hierarchy, c, c2)\n",
    "        except nx.exception.NetworkXNoPath as e:\n",
    "            length = 999\n",
    "        lengths.append(length)\n",
    "    min_length = min(lengths)\n",
    "    closest = cs[lengths.index(min_length)]\n",
    "    count_min = lengths.count(min_length)\n",
    "    return closest\n",
    "\n",
    "def get_closest_relevant_class(c):\n",
    "    return get_closest_class(c, only_relevant_types_dict)\n",
    "\n",
    "def is_subclass_of_any_relevant_class(c):\n",
    "    return any(map(lambda x: is_subclass_of(c, x), only_relevant_types_dict))\n",
    "\n",
    "def get_relevant_type(ide):\n",
    "    relevant_type = None\n",
    "    if ide in all_instances_and_types_dict:\n",
    "        types = all_instances_and_types_dict[ide]\n",
    "        if len(types) == 1:\n",
    "            t = types.pop(); types.add(t)\n",
    "            if is_subclass_of_any_relevant_class(t):\n",
    "                relevant_type = get_closest_relevant_class(t)\n",
    "        else:\n",
    "            relevant_candidates = set()\n",
    "            for t in types:\n",
    "                if is_subclass_of_any_relevant_class(t):\n",
    "                    relevant_type = get_closest_relevant_class(t)\n",
    "                    relevant_candidates.add(relevant_type)\n",
    "            if relevant_candidates:\n",
    "                # WARNING: if there is more than one relevant_candidates, then it returns only one of them\n",
    "                relevant_type = relevant_candidates.pop(); relevant_candidates.add(relevant_type)\n",
    "    return relevant_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_value(prop_inst):\n",
    "    try:\n",
    "        main_info = prop_inst['mainsnak'] # for properties themselves\n",
    "    except KeyError as e:\n",
    "        main_info = prop_inst # for qualifiers\n",
    "    prop_type = main_info['datavalue']['type']\n",
    "    if prop_type == 'wikibase-entityid':\n",
    "        value = 'Q' + str(main_info['datavalue']['value']['numeric-id'])\n",
    "    elif prop_type == 'string':\n",
    "        value = str(main_info['datavalue']['value'])\n",
    "    elif prop_type == 'time':\n",
    "        value = str(main_info['datavalue']['value']['time'][1:11])\n",
    "    elif prop_type == 'monolingualtext':\n",
    "        value = str(main_info['datavalue']['value']['text'])\n",
    "    else:\n",
    "        # WARNING: Unknown property type\n",
    "        raise Exception('Unknown property type')\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_relevant_instances_dict = {} # all relevant information for instances of relevant types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1630\n",
      "Count: 915\n",
      "Error: 2\n",
      "CPU times: user 5.92 s, sys: 20 ms, total: 5.94 s\n",
      "Wall time: 5.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total = 0\n",
    "count = 0\n",
    "error = 0\n",
    "with open('data/wikidata-20150907-star_trek.json') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            total += 1\n",
    "            cleaned = line.strip()[:-1]\n",
    "            d = json.loads(cleaned) # keys: ['type', 'labels', 'descriptions', 'claims', 'aliases', 'sitelinks', 'id']\n",
    "            ide = d['id']\n",
    "            typ = get_relevant_type(ide)\n",
    "            if typ:\n",
    "                if 'en' in d['labels']:\n",
    "                    name = d['labels']['en']['value']\n",
    "                else:\n",
    "                    name = ''\n",
    "                if 'enwiki' in d['sitelinks']:\n",
    "                    wikilink = d['sitelinks']['enwiki']['title']\n",
    "                else:\n",
    "                    wikilink = ''\n",
    "                if 'en' in d['descriptions']:\n",
    "                    description = d['descriptions']['en']['value']\n",
    "                else:\n",
    "                    description = ''\n",
    "                info = {\n",
    "                    'id': ide,\n",
    "                    'type': typ,\n",
    "                    'name': name,\n",
    "                    'wikilink': wikilink,\n",
    "                    'description': description,\n",
    "                    'properties': {},\n",
    "                }\n",
    "                for prop in d['claims']:\n",
    "                    if prop in only_relevant_properties_dict and prop != 'P31' and prop != 'P279':\n",
    "                        values = []\n",
    "                        for prop_inst in d['claims'][prop]:\n",
    "                            p_value = get_value(prop_inst)\n",
    "                            qualifiers = {}\n",
    "                            if 'qualifiers' in prop_inst:\n",
    "                                for q in prop_inst['qualifiers']:\n",
    "                                    if q in only_relevant_properties_dict:\n",
    "                                        q_values = []\n",
    "                                        for q_inst in prop_inst['qualifiers'][q]:\n",
    "                                            q_value = get_value(q_inst)\n",
    "                                            q_values.append(q_value)\n",
    "                                        qualifiers[q] = q_values\n",
    "                            values.append({'value': p_value, 'qualifiers': qualifiers})\n",
    "                        info['properties'][prop] = values\n",
    "                only_relevant_instances_dict[ide] = info\n",
    "                count += 1\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "print('Total:', total)\n",
    "print('Count:', count)\n",
    "print('Error:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(only_relevant_instances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Double check\n",
    "for ide in only_relevant_instances_dict:\n",
    "    assert(only_relevant_instances_dict[ide]['type'] in only_relevant_types_dict)\n",
    "    for prop in only_relevant_instances_dict[ide]['properties']:\n",
    "        assert(prop in only_relevant_properties_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickle/star-trek_only_relevant_instances_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(only_relevant_instances_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
